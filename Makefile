.PHONY: install scrape scrape_search_results jupyter backend frontend

install:
	@echo "ğŸ“¦ Installing Python dependencies with uv..."
	@uv sync
	@echo ""
	@echo "ğŸ­ Installing Playwright browsers..."
	@uv run playwright install chromium
	@echo ""
	@echo "âœ… Installation complete!"
	@echo ""
	@echo "Usage:"
	@echo "  make scrape               # Scrape listings"
	@echo "  make scrape_search_results  # Scrape search pages"
	@echo "  make jupyter              # Open Jupyter for data processing"

jupyter:
	@echo "ğŸ“Š Starting Jupyter notebook..."
	@echo ""
	@echo "ğŸ’¡ Open 'househunter_workflow.ipynb' to process and analyze data"
	@echo ""
	@uv run jupyter notebook

scrape:
	@echo "ğŸ•·ï¸  Starting manual scraper..."
	@echo "ğŸ“‹ Checking Chrome status..."
	@if curl -s http://localhost:9222/json/version >/dev/null 2>&1; then \
		echo "âœ… Chrome already running with remote debugging"; \
	else \
		echo "ğŸŒ Launching Chrome with remote debugging..."; \
		bash start_chrome.sh; \
		sleep 2; \
	fi
	@echo ""
	@echo "ğŸ’¾ Scraped data will be saved to: data/scraped/YYYY_MM_DD/"
	@echo ""
	@uv run python -m src.backend.manual_scraper

scrape_search_results:
	@echo "ğŸ” Starting search results scraper..."
	@echo "ğŸ“‹ Checking Chrome status..."
	@if curl -s http://localhost:9222/json/version >/dev/null 2>&1; then \
		echo "âœ… Chrome already running with remote debugging"; \
	else \
		echo "ğŸŒ Launching Chrome with remote debugging..."; \
		bash start_chrome.sh; \
		sleep 2; \
	fi
	@echo ""
	@echo "ğŸ’¾ Scraped data will be saved to: data/scraped/YYYY_MM_DD/search_results/"
	@echo ""
	@uv run python -m src.backend.manual_scraper_search

backend:
	uv run uvicorn src.backend.api.main:app --reload --port 8000

frontend:
	cd src/frontend && npm run dev
